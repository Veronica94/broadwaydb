require(plyr)
require(ggplot2)
require(tm)
require(topicmodels)

setwd("~/broadwaydb/analysis/")

songs <- read.csv('../data/songs.csv', stringsAsFactors=FALSE)
songs <- songs[,c("show_name", "song_name", "wiki_name", "book", "music", "lyrics_by",
                  "year", "broadway", "off_broadway", "song_count", 
                  "spotify_duration", "spotify_popularity", "spotify_track_index",
                  "spotify_track_name", "song_density","num_unique_words",
                  "vocab_diversity", "show_syllable_count",
                  "show_word_count", "album_duration", "show_density", "show_popularity",
                  "spotify_album_year", "song_diversity", "song_unique_words",
                  "song_word_count", "show_lyrics", "lyrics")]

shows <- songs[,c("show_name", "wiki_name", "book", "music", "lyrics_by",
                  "year", "broadway", "off_broadway", "song_count", "num_unique_words",
                  "vocab_diversity", "show_syllable_count",
                  "show_word_count", "album_duration", "show_density", "show_popularity",
                  "spotify_album_year", "show_lyrics")]
shows <- unique(shows)


#####################
# Topic Modeling
#####################

# Return a vector of stopwords from an external file
get.stopwords <- function(){
  words <- read.table('../data/stopwords.txt', sep='\n', stringsAsFactors=FALSE)
  return(words)
}

# Given a vector of strings, return a document term matrix
get.dtm <- function(doc.vec){
  doc.corpus <- Corpus(VectorSource(doc.vec))
  extendedstopwords <- get.stopwords()$V1
  doc.corpus <- tm_map(doc.corpus, tolower)
  doc.corpus <- tm_map(doc.corpus, stripWhitespace)
  doc.corpus <- tm_map(doc.corpus, removePunctuation)
  doc.corpus <- tm_map(doc.corpus, stripWhitespace)
  doc.corpus <- tm_map(doc.corpus, removeWords, extendedstopwords)
  doc.corpus <- tm_map(doc.corpus, stripWhitespace)
  control <- list(stopwords=FALSE,
                  removePunctuation=FALSE,
                  removeNumbers=TRUE,
                  minDocFreq=2)
  doc.dtm <- DocumentTermMatrix(doc.corpus, control)
  return(doc.dtm)
}

# ##### BY SHOW #######
# # get document term matrix of show lyrics
# show.dtm <- get.dtm(shows$show_lyrics)
# 
# # get topic model 
# k <- 2
# show.lda.model = LDA(show.dtm, k)
# 
# # see terms generated by model
# terms(show.lda.model, 50)
# 
# shows.topics <- posterior(show.lda.model, show.dtm)$topics
# df.shows.topics <- as.data.frame(shows.topics)


##### BY SONG #######
# get document term matrix of show lyrics
song.dtm <- get.dtm(songs$lyrics)

# get topic model 
k <- 3
song.lda.model = LDA(song.dtm, k)

# see terms generated by model
terms(song.lda.model, 50)

##################
# PLOTS/GRAPHS
##################
# count avg vocab diversity for each lyricist
lyricist_diversity <- ddply(shows, .(lyrics_by), summarize, show_count=length(show_name), avg_diversity=mean(vocab_diversity))

# Look at broadway vs not broadway
on_broadway <- ddply(shows, .(broadway), summarize, num_unique_words=mean(vocab_diversity)) 

# distribution of song duration
ggplot(songs, aes(x=spotify_duration)) + geom_density()

# distribution of song popularity
ggplot(songs, aes(x=spotify_popularity)) + geom_density()

# distribution of vocab diversity
ggplot(shows, aes(x=vocab_diversity)) + geom_density()

# Which shows are most popular on spotify?
show.popularity <- shows[,c("show_name", "show_popularity", "spotify_album_year")]
show.popularity <- subset(show.popularity, show_popularity > 0)
show.popularity$show_name <- replace(show.popularity$show_name, show.popularity$show_name=="Funny Thing Happened On The Way To The Forum, A", "A Funny Thing Happened...")
p <- ggplot(show.popularity, aes(x=reorder(show_name,show_popularity), y=show_popularity, fill=spotify_album_year))+ 
  geom_bar(stat="identity") +  
  coord_flip() +
  xlab("") + 
  ylab("Spotify Popularity") + 
  scale_colour_brewer() + 
  scale_fill_continuous(name="Album Year")
ggsave("../figures/show_popularity.png", plot=p, width=10, height=16)

# Which songs are most repetitive?
song.repetition <- songs[,c("song_name", "show_name", "song_diversity", "song_word_count")]
song.repetition$song_diversity = 1 - song.repetition$song_diversity
song.repetition <- subset(song.repetition, song_word_count>100)
song.repetition <- song.repetition[order(-song.repetition$song_diversity),]
song.repetition <- song.repetition[1:20,]
ggplot(song.repetition, aes(x=reorder(paste(song_name,show_name, sep=', '), song_diversity), y=song_diversity)) + 
  xlab("") + 
  ylab("Repetitiousness") + 
  geom_bar(stat="identity") + 
  coord_flip()

# Which shows are most repetitive?
show.repetition <- shows[,c("show_name", "vocab_diversity")]
show.repetition <- show.repetition[order(show.repetition$vocab_diversity),]
show.repetition <- show.repetition[1:20,]
ggplot(show.repetition, aes(x=reorder(show_name, -vocab_diversity), y=vocab_diversity)) +
  geom_bar(stat="identity") + 
  coord_flip()

